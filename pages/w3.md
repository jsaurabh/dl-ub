---
layout: page
title: CNNs and RNNs
tagline: Diving into the Cool Stuff
description: Week3 material w/ code
---

Table of Contents:
1. [Overview](#ovrvw)
2. [Concepts](#concepts)
3. [Architecture](#arch)
3. [Reading](#reading)

## CNN Overview <a name="ovrvw"></a>

Convolutional Neural Networks are the preferred way of using deep neural networks on visual data. They are preferred to fully connected(dense) layers because of their ability to capture spatial information, downsample an image to find increasingly granular patterns and do it all more efficiently than a fully connected layer would. Unlike an FC layer, CNNs don't require flattening of the input image and instead rely on the concept of a receptive field to make sense of the input.

A receptive field(aka kernel, filter) goes through different parts of the image successively and performs a computation which leads to one numerical input for each location in the image. Represented as a 2D matrix, a receptive field is composed of weight parameters which are element wise multiplied with the pixel values in the image.

![](https://miro.medium.com/max/395/0*1PSMTM8Brk0hsJuF.)

The receptive field convolves over the image input, across its receptive field and does an element-wise multiplication. It then moves(slides) to a different part of the image and does the same computation again, till the image has been processed completely. This leads to a feature map(activation map) for the image, which represents the activated output for the given image. Depending on the depth of the network, different layers will recognize different kinds of features and the deeper you go, the more fine it gets. 


## CNN Concepts<a name="concepts"></a>

### Stride
Padding and Stride are two parameters that allow us to manipulate how a filter convolves over the input. Stride represents the shift that each filters makes over sucessive iterations on the input, allowing it to capture spatial information around the pixel it is currently looking at. 

### Padding
Padding will pad the border of the input ie. zero padding pads zeros around the border of the image. Padding is relevant here because it ensures that the successive layers in the network are able to operate on the entire image, rather than decreasing inputs which are a result of the convolution operation. 

Two types of padding:
    1. Full: Zero pads the input such that all pixels are visited exactly the same number of times. 
    2. Same: Pads the input such that the output feature map has the same size as the input feature map

### Pooling
Pooling layers are an important part of any CNN architecture and are used for downsampling an image. This lets us compress the parameters that the next layer needs to operate on, reducing training time. The biggest advantage to pooling is invariance. 


## A Typical CNN Architecture<a name="arch"></a>

A typical CNN architecture consists of many of the concepts we've talked about today and over the last 2 weeks. The convolutional layer is always the first layer in a CNN, operating on the input with a given receptive field and stride and padding. This leads to activation maps, which are then passed through an activation function(ReLU). This is generally followed by a pooling layer(max-pool). This chain of layers constitutes one block in a CNN. 

There can be many number of blocks. The last CNN block is connected to a Fully Connected layer with an arbitrary number of inputs. However, the last FC layer will have as many neurons as the number of target variables. This last FC layer is attached to a softmax classifier which looks at the final output and assigns a class variable to the input.

A typical CNN architecture looks as follows:
![](https://miro.medium.com/max/2156/1*LTRcAyl6zuuJvpU-5KECZA.png)

**NOTE:** 
The above figure was taken as is from a [Medium](https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac) blog post.

The earlier layers in a CNN learn to understand lower level filters such as edges, corners. The latter layers will learn to detect more higher level features. In a network meant for classifying human faces, the latter layers will learn to detect features such as eyes, hands, nose etc. 

For those interested in visualizing the output of individual layers in a CNN, there is an excellent paper by [Zeiler and Fergus](https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf)

Some sample images from their paper are presented here:

![](https://adeshpande3.github.io/assets/deconvnet.png)

![](https://adeshpande3.github.io/assets/deconvnet2.png)

For a dive into different CNN architectures, click [here](cnn-architecture.html)

## Reading <a name="reading"></a>

1. [Visualizing and Understanding Convolutional Neural Networks](https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf)
2. [Chapter 6](http://neuralnetworksanddeeplearning.com/chap6.html)